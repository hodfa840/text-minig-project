# Comparative Study of Deep Learning Models for Text Classification: LSTM, CNN with GloVe Embedding, and BERT


 This project explores the use of various deep learning models for text classification on the Yahoo Answers dataset. The models considered are Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN) with GloVe embedding, and Bidirectional Encoder Representations from Transformers (BERT). For LSTM and CNN models, pre-trained GloVe embeddings are used, while for BERT, pre-trained BERT embeddings are used. The performance of each model is evaluated using accuracy and ROC AUC score metrics.
 
 ## Dataset
 
 The dataset can be downloaded from: https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M?resourcekey=0-TLwzfR2O-D2aPitmn5o9VQ
